{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "T5PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08317f9298b345768a5ca7034ead2fab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c3e94b6d31bb43979cfb4564ea07d8a6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_253a513950ae4a3bbf646d50ee807baf",
              "IPY_MODEL_9da15868b1b44cca858dce7e35008d58"
            ]
          }
        },
        "c3e94b6d31bb43979cfb4564ea07d8a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "253a513950ae4a3bbf646d50ee807baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0ced9599f06341a58496165735e14fb8",
            "_dom_classes": [],
            "description": "Epoch 4: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5973ae4686c546508334e380d079e725"
          }
        },
        "9da15868b1b44cca858dce7e35008d58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_54b5c313383940babe1098b3aed2ab21",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [01:04&lt;00:00, 21.62s/it, loss=1.97, v_num=0, val_loss=1.540]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3131badca71b4896bde16bccc68ef491"
          }
        },
        "0ced9599f06341a58496165735e14fb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5973ae4686c546508334e380d079e725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "54b5c313383940babe1098b3aed2ab21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3131badca71b4896bde16bccc68ef491": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oso052g4QMLY"
      },
      "source": [
        "!pip install --quiet transformers==4.1.1\n",
        "!pip install --quiet pytorch-lightning=1.1.2\n",
        "!pip install --quiet tokenizers==0.9.4\n",
        "!pip install --quiet sentencepiece==0.1.94"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HE_GxPL3QqhW"
      },
      "source": [
        "import argparse\n",
        "import glob\n",
        "import os\n",
        "import logging\n",
        "import json\n",
        "import re\n",
        "from itertools import chain\n",
        "from string import punctuation\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from termcolor import colored\n",
        "import textwrap\n",
        "\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import Dataset,DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "from transformers import(\n",
        "    AdamW,\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer,\n",
        "    get_linear_schedule_with_warmup\n",
        ")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0l_YR81Spiy",
        "outputId": "21ea2137-33d2-46f0-dcf7-9dcb079f261f"
      },
      "source": [
        "pl.seed_everything(3)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Global seed set to 3\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM_VXeo3Skn0"
      },
      "source": [
        "question = {'context': 'In 1799 The Manhattan Company is founded. The Manhattan Company, JPMorgan Chase earliest predecessor institution, is chartered by the New York State legislature to supply \"pure and wholesome\" drinking water to the city\\'s growing population.  Among its founders are Alexander Hamilton and Aaron Burr. A provision in the charter allows The Manhattan Company to use its surplus capital for banking operations.  Within five months, The Bank of The Manhattan Company opens for business, becoming the second commercial bank in New York City after Hamilton’s Bank of New York.  With his banking monopoly broken, Hamilton severs his association with the water company',\n",
        "            'question': 'When was The Manhattan Company founded ? ',\n",
        "            'answer':'1799'}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "k7pxcRwbUtbe",
        "outputId": "a8c7e149-e909-405c-b037-2b163c11b3ee"
      },
      "source": [
        "datarows = []\n",
        "datarows.append({\n",
        "    \"question\": question['question'],\n",
        "    \"context\" : question['context'],\n",
        "    \"answer_text\": question['answer']\n",
        "})\n",
        "datarows.append({\n",
        "    \"question\": 'Who founded The Manhattan Company ?',\n",
        "    \"context\" : question['context'],\n",
        "    \"answer_text\": 'Alexander Hamilton and Aaron Burr'\n",
        "})\n",
        "datarows.append({\n",
        "    \"question\": 'What happened in 1799 ?',\n",
        "    \"context\" : question['context'],\n",
        "    \"answer_text\": question['context']\n",
        "})\n",
        "df = pd.DataFrame(datarows)\n",
        "df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "      <th>answer_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>When was The Manhattan Company founded ?</td>\n",
              "      <td>In 1799 The Manhattan Company is founded. The ...</td>\n",
              "      <td>1799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Who founded The Manhattan Company ?</td>\n",
              "      <td>In 1799 The Manhattan Company is founded. The ...</td>\n",
              "      <td>Alexander Hamilton and Aaron Burr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What happened in 1799 ?</td>\n",
              "      <td>In 1799 The Manhattan Company is founded. The ...</td>\n",
              "      <td>In 1799 The Manhattan Company is founded. The ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    question  ...                                        answer_text\n",
              "0  When was The Manhattan Company founded ?   ...                                               1799\n",
              "1        Who founded The Manhattan Company ?  ...                  Alexander Hamilton and Aaron Burr\n",
              "2                    What happened in 1799 ?  ...  In 1799 The Manhattan Company is founded. The ...\n",
              "\n",
              "[3 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rkZut_bVHob"
      },
      "source": [
        "m_name = 't5-base'\n",
        "tokenizer = T5Tokenizer.from_pretrained(m_name)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nueXOMW3XVD9"
      },
      "source": [
        "# sample_question = df.iloc[0]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhJYJAHZW6Gq"
      },
      "source": [
        "# encoding = tokenizer(\n",
        "#     sample_question['question'],\n",
        "#     sample_question['context'],\n",
        "#     max_length=396,\n",
        "#     padding=\"max_length\",\n",
        "#     truncation=\"only_second\",\n",
        "#     return_attention_mask=True,\n",
        "#     add_special_tokens=True,\n",
        "#     return_tensors=\"pt\"\n",
        "# )"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO8Z_eFMX1gu"
      },
      "source": [
        "# answer_encoding = tokenizer( \n",
        "#     sample_question['answer_text'],\n",
        "#     max_length=32,\n",
        "#     padding=\"max_length\",\n",
        "#     truncation=True,\n",
        "#     return_attention_mask=True,\n",
        "#     add_special_tokens=True,\n",
        "#     return_tensors=\"pt\"\n",
        "# )"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bolbjtFnX9R1"
      },
      "source": [
        "# model = T5ForConditionalGeneration.from_pretrained(m_name, return_dict=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fksM0mwnZL8Z"
      },
      "source": [
        "# output = model(\n",
        "#     input_ids=encoding[\"input_ids\"],\n",
        "#     attention_mask=encoding[\"attention_mask\"],\n",
        "#     labels = answer_encoding[\"input_ids\"]\n",
        "# )"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFhaiPCmZfoF"
      },
      "source": [
        "# output.logits.shape, output.loss"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOI6_jE-nIEH"
      },
      "source": [
        "class QADataset(Dataset):\n",
        "  def __init__(\n",
        "      self,\n",
        "      data: pd.DataFrame,\n",
        "      tokenizer: T5Tokenizer,\n",
        "      source_max_token_length: int = 396,\n",
        "      target_max_token_length: int = 32\n",
        "  ):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.data = data\n",
        "    self.source_max_token_length = source_max_token_length\n",
        "    self.target_max_token_length = target_max_token_length\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self,index: int):\n",
        "    data_row = self.data.iloc[index]\n",
        "  \n",
        "    source_encoding = tokenizer(\n",
        "      data_row['question'],\n",
        "      data_row['context'],\n",
        "      max_length=self.source_max_token_length,\n",
        "      padding=\"max_length\",\n",
        "      truncation=\"only_second\",\n",
        "      return_attention_mask=True,\n",
        "      add_special_tokens=True,\n",
        "      return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    target_encoding = tokenizer(\n",
        "      data_row['answer_text'],\n",
        "      max_length=self.target_max_token_length,\n",
        "      padding=\"max_length\",\n",
        "      truncation=True,\n",
        "      return_attention_mask=True,\n",
        "      add_special_tokens=True,\n",
        "      return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    labels = target_encoding[\"input_ids\"]\n",
        "    labels[labels == 0] = -100\n",
        "\n",
        "    return dict(\n",
        "        question=data_row[\"question\"],\n",
        "        context=data_row[\"context\"],\n",
        "        answer_text=data_row[\"answer_text\"],\n",
        "        input_ids=source_encoding[\"input_ids\"].flatten(),\n",
        "        labels=labels.flatten()\n",
        "    )\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpDwIrjrx6qn"
      },
      "source": [
        "class QADataModel(pl.LightningDataModule):\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      train_df: pd.DataFrame,\n",
        "      tokenizer: T5Tokenizer,\n",
        "      batch_size: int=8,\n",
        "      source_max_token_length = 396,\n",
        "      target_max_token_length = 32\n",
        "  ):\n",
        "    super().__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.train_df = train_df\n",
        "    self.train_dataset = None\n",
        "    self.tokenizer = tokenizer\n",
        "    self.source_max_token_length = source_max_token_length\n",
        "    self.target_max_token_length = target_max_token_length\n",
        "\n",
        "  def setup(self):\n",
        "    self.train_dataset = QADataset(\n",
        "        self.train_df,\n",
        "        self.tokenizer,\n",
        "        self.source_max_token_length,\n",
        "        self.target_max_token_length\n",
        "    )\n",
        "  \n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(\n",
        "        self.train_dataset,\n",
        "        batch_size=self.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2\n",
        "    )\n",
        "    "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPdzam4RzRm4"
      },
      "source": [
        "BATCH_SIZE = 1\n",
        "EPOCHS = 5\n",
        "data_module = QADataModel(df,tokenizer,batch_size=BATCH_SIZE)\n",
        "data_module.setup()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4WUcxFgbIva"
      },
      "source": [
        "class QAModel(pl.LightningModule):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.model = T5ForConditionalGeneration.from_pretrained(m_name,return_dict = True)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask, labels=None):\n",
        "    output = self.model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        labels=labels\n",
        "    )\n",
        "    return output.loss, output.logits\n",
        "  \n",
        "  def training_step(self, batch, batch_idx):\n",
        "    input_ids = batch[\"input_ids\"]\n",
        "    # attention_mask = batch['attention_mask']\n",
        "    labels = batch[\"labels\"]\n",
        "    loss, outputs = self(input_ids,None,labels)\n",
        "    self.log(\"val_loss\",loss,prog_bar=True,logger=True)\n",
        "    return loss\n",
        "  \n",
        "  def configure_optimizers(self):\n",
        "    return AdamW(self.parameters(),lr=0.001)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXnIOSPFbqa3",
        "outputId": "be5df1cb-bd57-486f-d57f-19e78500cabe"
      },
      "source": [
        "model = QAModel()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at t5-base were not used when initializing T5ForConditionalGeneration: ['decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight']\n",
            "- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbwN6t8BkjcP",
        "outputId": "2c6a12a7-9bb8-4bc9-ba87-64792c52236e"
      },
      "source": [
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning import Trainer\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath=\"checkpoints\",\n",
        "    filename=\"best-checkpoint\",\n",
        "    save_top_k=1,\n",
        "    verbose=True,\n",
        "    monitor='val_loss',\n",
        "    mode=\"min\"\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning: Checkpoint directory checkpoints exists and is not empty.\n",
            "  warnings.warn(*args, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiG5hgFsk45S",
        "outputId": "b98f032d-2686-4604-9345-4c9eac8d0c5c"
      },
      "source": [
        "trainer = Trainer(\n",
        "    checkpoint_callback=checkpoint_callback,\n",
        "    max_epochs=EPOCHS,\n",
        "    progress_bar_refresh_rate=30\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: None, using: 0 TPU cores\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDzGVehplePF"
      },
      "source": [
        "# %load_ext tensorboard"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q9BTx4elwho"
      },
      "source": [
        "# %tensorboard --logdir ./lightning_logs"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsGTtW02_xhz"
      },
      "source": [
        "!rm -r lightning_logs"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318,
          "referenced_widgets": [
            "08317f9298b345768a5ca7034ead2fab",
            "c3e94b6d31bb43979cfb4564ea07d8a6",
            "253a513950ae4a3bbf646d50ee807baf",
            "9da15868b1b44cca858dce7e35008d58",
            "0ced9599f06341a58496165735e14fb8",
            "5973ae4686c546508334e380d079e725",
            "54b5c313383940babe1098b3aed2ab21",
            "3131badca71b4896bde16bccc68ef491"
          ]
        },
        "id": "0K34mwQWl0O5",
        "outputId": "401b8ed0-91df-4f51-e18d-6778559ce5ca"
      },
      "source": [
        "trainer.fit(model, data_module)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name  | Type                       | Params\n",
            "-----------------------------------------------------\n",
            "0 | model | T5ForConditionalGeneration | 222 M \n",
            "-----------------------------------------------------\n",
            "222 M     Trainable params\n",
            "0         Non-trainable params\n",
            "222 M     Total params\n",
            "891.614   Total estimated model params size (MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08317f9298b345768a5ca7034ead2fab",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, global step 2: val_loss reached 4.76596 (best 4.76596), saving model to \"/content/checkpoints/best-checkpoint-v1.ckpt\" as top 1\n",
            "Epoch 1, global step 5: val_loss reached 2.99939 (best 2.99939), saving model to \"/content/checkpoints/best-checkpoint-v1.ckpt\" as top 1\n",
            "Epoch 2, global step 8: val_loss reached 1.13788 (best 1.13788), saving model to \"/content/checkpoints/best-checkpoint-v1.ckpt\" as top 1\n",
            "Epoch 3, global step 11: val_loss reached 0.87239 (best 0.87239), saving model to \"/content/checkpoints/best-checkpoint-v1.ckpt\" as top 1\n",
            "Epoch 4, global step 14: val_loss reached 0.49230 (best 0.49230), saving model to \"/content/checkpoints/best-checkpoint-v1.ckpt\" as top 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38CWHj7WJfhU",
        "outputId": "8e562ac9-5a11-4c30-82ee-73ec1fd0a4bb"
      },
      "source": [
        "ls checkpoints"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best-checkpoint.ckpt  best-checkpoint-v1.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7d2icuGD_7t",
        "outputId": "1e4c1e01-4025-4a9c-8e90-05b17ba824e9"
      },
      "source": [
        "trained_model = QAModel.load_from_checkpoint(\"checkpoints/best-checkpoint-v1.ckpt\")\n",
        "trained_model.freeze()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at t5-base were not used when initializing T5ForConditionalGeneration: ['decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight']\n",
            "- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1W33oD2Ecng"
      },
      "source": [
        "def generate_answer(question):\n",
        "  source_encoding = tokenizer(\n",
        "      question[\"question\"],\n",
        "      question[\"context\"],\n",
        "      max_length=396,\n",
        "      padding=\"max_length\",\n",
        "      truncation=\"only_second\",\n",
        "      return_attention_mask=True,\n",
        "      add_special_tokens=True,\n",
        "      return_tensors=\"pt\"\n",
        "  )\n",
        "\n",
        "  generated_ids = trained_model.model.generate(\n",
        "      input_ids=source_encoding[\"input_ids\"],\n",
        "      attention_mask=source_encoding[\"attention_mask\"],\n",
        "      num_beams=3,\n",
        "      max_length=80,\n",
        "      repetition_penalty=1.0,\n",
        "      early_stopping=True,\n",
        "      use_cache=True\n",
        "  )\n",
        "\n",
        "  preds = [\n",
        "           tokenizer.decode(generated_id,skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
        "           for generated_id in generated_ids\n",
        "  ]\n",
        "\n",
        "  return \"\".join(preds)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cJh59oJFt2D"
      },
      "source": [
        "datarows = []\n",
        "datarows.append({\n",
        "    \"question\": 'when was The Manhattan Company founded ?',\n",
        "    \"context\" : question['context']\n",
        "})\n",
        "datarows.append({\n",
        "    \"question\": 'What happened in 1799 ?',\n",
        "    \"context\" : question['context']\n",
        "})\n",
        "datarows.append({\n",
        "    \"question\": 'where did Chase open its first environmentally friendly branch ?',\n",
        "    \"context\" : 'In 2007, Chase opens its first environmentally friendly branch in Denver.'\n",
        "})\n",
        "datarows.append({\n",
        "    \"question\": 'When did Chase open its first environmentally friendly branch ?',\n",
        "    \"context\" : 'In 2007, Chase opens its first environmentally friendly branch in Denver.'\n",
        "})\n",
        "datarows.append({\n",
        "    \"question\": 'What happened in the year 1998 ?',\n",
        "    \"context\" : 'In the year 1998, Banc One merges with First Chicago NBD, The new firm, retaining the name Bank One Corporation, chooses Chicago as its headquarters and becomes the fourth largest bank in the U.S. and the world\\'s largest Visa credit card issuer.'\n",
        "})\n",
        "datarows.append({\n",
        "    \"question\": 'When did Banc One merge with First Chicago NBD ?',\n",
        "    \"context\" : 'In the year 1998, Banc One merges with First Chicago NBD, The new firm, retaining the name Bank One Corporation, chooses Chicago as its headquarters and becomes the fourth largest bank in the U.S. and the world\\'s largest Visa credit card issuer.'\n",
        "})\n",
        "datarows.append({\n",
        "    \"question\": 'Where is the headquaters located ?',\n",
        "    \"context\" : 'In the year 1998, Banc One merges with First Chicago NBD, The new firm, retaining the name Bank One Corporation, chooses Chicago as its headquarters and becomes the fourth largest bank in the U.S. and the world\\'s largest Visa credit card issuer.'\n",
        "})\n",
        "v_df = pd.DataFrame(datarows)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRe-XMCFGEDl",
        "outputId": "49435298-c20c-46e6-ceef-5e79f9670090"
      },
      "source": [
        "sample = v_df.iloc[1]\n",
        "sample"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "question                              What happened in 1799 ?\n",
              "context     In 1799 The Manhattan Company is founded. The ...\n",
              "Name: 1, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZqnnPPDDGE-d",
        "outputId": "817ada1a-25e0-49cd-d66b-ded3202e9ffc"
      },
      "source": [
        "generate_answer(sample)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1799'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwXQUfW-GLID"
      },
      "source": [
        ""
      ],
      "execution_count": 59,
      "outputs": []
    }
  ]
}